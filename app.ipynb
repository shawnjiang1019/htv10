{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c9d68918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import add_messages, StateGraph, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "from elevenlabs.client import ElevenLabs\n",
    "import json\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import pygame\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys\n",
    "gemini_key = os.getenv('GEMINI_API_KEY')\n",
    "elevenlabs_key = os.getenv('ELEVENLABS_API_KEY')\n",
    "\n",
    "# Initialize pygame mixer for audio playback\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Initialize ElevenLabs client\n",
    "elevenlabs_client = ElevenLabs(api_key=elevenlabs_key)\n",
    "\n",
    "genai.configure(api_key=gemini_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00cc04dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text-to-speech function created!\n"
     ]
    }
   ],
   "source": [
    "def text_to_speech(text, voice_id=\"JBFqnCBsd6RMkjVDRZzb\"):\n",
    "    \"\"\"Convert text to speech using Eleven Labs and pygame\"\"\"\n",
    "    try:\n",
    "        # Generate audio using the correct API\n",
    "        audio = elevenlabs_client.text_to_speech.convert(\n",
    "            text=text,\n",
    "            voice_id=voice_id,\n",
    "            model_id=\"eleven_multilingual_v2\",\n",
    "            output_format=\"mp3_44100_128\",\n",
    "        )\n",
    "        \n",
    "        # Convert the audio to bytes\n",
    "        audio_bytes = b\"\".join(audio)\n",
    "        \n",
    "        # Create a temporary file with a unique name\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_file:\n",
    "            temp_file.write(audio_bytes)\n",
    "            temp_filename = temp_file.name\n",
    "        \n",
    "        # Stop any currently playing music\n",
    "        pygame.mixer.music.stop()\n",
    "        \n",
    "        # Load and play the new audio file\n",
    "        pygame.mixer.music.load(temp_filename)\n",
    "        pygame.mixer.music.play()\n",
    "        \n",
    "        # Wait for playback to finish\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.wait(100)\n",
    "        \n",
    "        # Clean up the temporary file\n",
    "        try:\n",
    "            os.unlink(temp_filename)\n",
    "        except OSError:\n",
    "            pass  # File might already be deleted\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating speech: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"âœ… Text-to-speech function created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db761bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Testing Updated Audio System...\n",
      "âœ… Audio test successful!\n"
     ]
    }
   ],
   "source": [
    "# Test the updated audio functionality\n",
    "print(\"ðŸŽµ Testing Updated Audio System...\")\n",
    "test_text = \"Hello! This is a test of the updated text-to-speech functionality for our debate agents.\"\n",
    "success = text_to_speech(test_text)\n",
    "if success:\n",
    "    print(\"âœ… Audio test successful!\")\n",
    "else:\n",
    "    print(\"âŒ Audio test failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f579d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Audio control functions added!\n"
     ]
    }
   ],
   "source": [
    "# Clean up any existing temp_audio.mp3 file\n",
    "try:\n",
    "    if os.path.exists(\"temp_audio.mp3\"):\n",
    "        os.unlink(\"temp_audio.mp3\")\n",
    "        print(\"Cleaned up existing temp_audio.mp3\")\n",
    "except OSError as e:\n",
    "    print(f\"Could not clean up temp_audio.mp3: {e}\")\n",
    "\n",
    "# Add audio control functions\n",
    "def stop_audio():\n",
    "    \"\"\"Stop any currently playing audio\"\"\"\n",
    "    pygame.mixer.music.stop()\n",
    "\n",
    "def pause_audio():\n",
    "    \"\"\"Pause currently playing audio\"\"\"\n",
    "    pygame.mixer.music.pause()\n",
    "\n",
    "def resume_audio():\n",
    "    \"\"\"Resume paused audio\"\"\"\n",
    "    pygame.mixer.music.unpause()\n",
    "\n",
    "print(\"âœ… Audio control functions added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e126ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Testing Full Debate System with Audio...\n",
      "================================================================================\n",
      "ðŸŽ¯ DEBATE TOPIC: Artificial Intelligence will improve education\n",
      "ðŸŽ§ Audio will play for each agent's response...\n",
      "================================================================================\n",
      "ðŸŽ¯ DEBATE TOPIC: Artificial Intelligence will improve education\n",
      "ðŸ“Š Rounds: 2\n",
      "================================================================================\n",
      "ðŸŽ§ Audio will play for each agent's response...\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¤ PROPONENT (Round 1):\n",
      "--------------------------------------------------\n",
      "Thank you. I am ready to begin.\n",
      "\n",
      "The proposition that Artificial Intelligence will improve education is not a speculative fantasy; it is an impending reality. To understand the transformative potential of AI in our classrooms, we can look to the clear and powerful precedent being set in another critical, human-centric field: healthcare.\n",
      "\n",
      "As the provided evidence consistently highlights, \"Artificial intelligence will significantly improve healthcare outcomes by enabling early disease detection, personalized treatment plans, and reducing medical errors through advanced diagnostic tools\" (Evidence 1-5). The core principles driving this revolutionâ€”personalization, early intervention, and data-driven supportâ€”are directly translatable to the challenges and opportunities within education.\n",
      "\n",
      "Letâ€™s draw the parallels. In medicine, AI enables \"early disease detection\"; in education, this becomes the early and accurate identification of learning gaps or developmental hurdles in a student. Instead of waiting for a failing grade on a test, AI can spot subtle patterns of misunderstanding in real-time.\n",
      "\n",
      "Furthermore, just as AI helps create \"personalized treatment plans\" for patients, it can generate truly personalized learning paths for students. It can adapt the curriculum, pace, and style of content to fit each individual's needs, moving us decisively beyond the limiting one-size-fits-all model of the past. This isn't about replacing teachers; it's about equipping them with a powerful diagnostic tool, freeing them from routine administrative tasks to focus on what matters most: mentoring, inspiring, and connecting with their students on a deeper level.\n",
      "\n",
      "The successful application of AI in a complex field like healthcare provides a clear and compelling roadmap. The same technology that personalizes medicine can, and will, personalize learning, leading to a future of more effective, equitable, and engaging education for all.\n",
      "\n",
      "ðŸ”Š Playing Proponent's response...\n"
     ]
    }
   ],
   "source": [
    "# Test the full debate system with audio\n",
    "print(\"ðŸš€ Testing Full Debate System with Audio...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test with a shorter debate to verify audio works\n",
    "test_claim = \"Artificial Intelligence will improve education\"\n",
    "print(f\"ðŸŽ¯ DEBATE TOPIC: {test_claim}\")\n",
    "print(\"ðŸŽ§ Audio will play for each agent's response...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run a short test debate\n",
    "result = test_debate(test_claim, max_rounds=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d158450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced voice options added!\n",
      "Available voices:\n",
      "  - proponent: JBFqnCBsd6RMkjVDRZzb\n",
      "  - conponent: EXAVITQu4vr4xnSDxMaL\n",
      "  - moderator: pNInz6obpgDQGcFmaJgB\n",
      "  - narrator: AZnzlk1XvdvUeBnXmlld\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a44624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemini model\n",
    "model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "print(\"Gemini model initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26470676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Testing Different Voice Options...\n",
      "==================================================\n",
      "\n",
      "ðŸ”Š Testing proponent voice (JBFqnCBsd6RMkjVDRZzb):\n",
      "âœ… proponent voice test successful!\n",
      "------------------------------\n",
      "\n",
      "ðŸ”Š Testing conponent voice (EXAVITQu4vr4xnSDxMaL):\n",
      "âœ… conponent voice test successful!\n",
      "------------------------------\n",
      "\n",
      "ðŸ”Š Testing moderator voice (pNInz6obpgDQGcFmaJgB):\n",
      "âœ… moderator voice test successful!\n",
      "------------------------------\n",
      "\n",
      "ðŸ”Š Testing narrator voice (AZnzlk1XvdvUeBnXmlld):\n",
      "âœ… narrator voice test successful!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24927001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242daeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    claim: str\n",
    "    messages: Annotated[list, add_messages]  # LangGraph message system\n",
    "    round_number: int\n",
    "    max_rounds: int\n",
    "    conversation_history: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e760e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGDebateAgent:\n",
    "\n",
    "    def __init__(self, name, position, model, db_vector):\n",
    "        self.name = name\n",
    "        self.position = position\n",
    "        self.model = model\n",
    "        self.db_vector = db_vector\n",
    "\n",
    "    def retrieve_evidence(self, query, top_k=5):\n",
    "        \"\"\"Retrieve evidence from vector database\"\"\"\n",
    "        evidence = []\n",
    "        \n",
    "        if self.db_vector:\n",
    "            try:\n",
    "                vector_results = self.db_vector.search(query, top_k)\n",
    "                for docs, score in vector_results:\n",
    "                    evidence.append({\n",
    "                        \"content\": docs.page_content, \n",
    "                        \"source\": docs.metadata.get('source', 'Unknown'),\n",
    "                        \"score\": score\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Vector DB error: {e}\")\n",
    "                \n",
    "        return evidence   \n",
    "\n",
    "    def generate_debate_response(self, state: State): \n",
    "        \"\"\"Generate a debate response using evidence\"\"\"\n",
    "        search_query = f\"{state['claim']} {self.position} arguments\"\n",
    "        evidence = self.retrieve_evidence(search_query, top_k=5)\n",
    "\n",
    "        evidence_context = \"\"\n",
    "        for i, ev in enumerate(evidence, 1):\n",
    "            evidence_context += f\"Evidence {i} ({ev['source']}): {ev['content']}...\\n\"\n",
    "\n",
    "        history_context = \"\"\n",
    "        if state['messages']:\n",
    "            history_context = \"Previous exchanges:\\n\"\n",
    "            for msg in state['messages']:\n",
    "                history_context += f\"{msg['role']}: {msg['content']}...\\n\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are {self.name}, a {self.position}ponent in a debate.\n",
    "\n",
    "DEBATE TOPIC: \"{state['claim']}\"\n",
    "\n",
    "ROUND: {state['round_number']}/{state['max_rounds']}\n",
    "\n",
    "{history_context}\n",
    "\n",
    "EVIDENCE TO SUPPORT YOUR {self.position.upper()} POSITION:\n",
    "{evidence_context}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Use the evidence above to support your {self.position} argument.\n",
    "2. Address any points made by the opponent.\n",
    "3. Be persuasive but respectful.\n",
    "4. Keep response concise and cite evidence where possible.\n",
    "\n",
    "Your {self.position} response:\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {e}\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ee67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9731da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pinecone index 'rag-debate-index' with OpenAI embeddings\n",
      "Multi Agents intialized\n"
     ]
    }
   ],
   "source": [
    "# Import VectorDB class\n",
    "from vector_db import VectorDB\n",
    "\n",
    "#initalize vector db\n",
    "pinecone_db = VectorDB(\"rag-debate-index\")\n",
    "\n",
    "pro_agent = RAGDebateAgent(\n",
    "    name=\"Proponent\",\n",
    "    position=\"pro\",\n",
    "    model = model,\n",
    "    db_vector = pinecone_db\n",
    ")\n",
    "\n",
    "con_agent = RAGDebateAgent(\n",
    "    name=\"Conponent\",\n",
    "    position=\"con\",\n",
    "    model = model,\n",
    "    db_vector = pinecone_db\n",
    ")\n",
    "\n",
    "print(\"Multi Agents intialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent node functions defined!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#agent node functions\n",
    "def pro_agent_node(state):\n",
    "    response = pro_agent.generate_debate_response(state)\n",
    "    \n",
    "    # Print and speak the response\n",
    "    print(f\"\\nðŸŽ¤ PROPONENT (Round {state['round_number']}):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(response)\n",
    "    print()\n",
    "    \n",
    "    # Convert to speech with enhanced audio system\n",
    "    print(\"ðŸ”Š Playing Proponent's response...\")\n",
    "    play_agent_audio(response, \"proponent\")\n",
    "    \n",
    "    # Update conversation history\n",
    "    new_entry = {\n",
    "        \"speaker\": \"Proponent\",\n",
    "        \"response\": response,\n",
    "        \"round\": state[\"round_number\"]\n",
    "    }\n",
    "\n",
    "    updated_history = state[\"conversation_history\"] + [new_entry]\n",
    "\n",
    "    return {\n",
    "        \"conversation_history\": updated_history,\n",
    "        \"round_number\": state[\"round_number\"] + 1\n",
    "    }\n",
    "\n",
    "def con_agent_node(state):\n",
    "    response = con_agent.generate_debate_response(state)\n",
    "\n",
    "    # Print and speak the response\n",
    "    print(f\"\\nðŸŽ¤ CONPONENT (Round {state['round_number']}):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(response)\n",
    "    print()\n",
    "    \n",
    "    # Convert to speech with enhanced audio system\n",
    "    print(\"ðŸ”Š Playing Conponent's response...\")\n",
    "    play_agent_audio(response, \"conponent\")\n",
    "    \n",
    "    # Update conversation history\n",
    "    new_entry = {\n",
    "        \"speaker\": \"Conponent\",\n",
    "        \"response\": response,\n",
    "        \"round\": state[\"round_number\"]\n",
    "    }\n",
    "\n",
    "    updated_history = state[\"conversation_history\"] + [new_entry]\n",
    "\n",
    "    return {\n",
    "        \"conversation_history\": updated_history,\n",
    "        \"round_number\": state[\"round_number\"] + 1\n",
    "    }\n",
    "\n",
    "def should_continue(state: State):\n",
    "    \"\"\"Determine if debate should continue\"\"\"\n",
    "    if state[\"round_number\"] >= state[\"max_rounds\"]:\n",
    "        return \"end\"\n",
    "    elif state[\"round_number\"] % 2 == 1:  # Odd rounds go to pro_agent\n",
    "        return \"pro_agent\"\n",
    "    else:  # Even rounds go to con_agent\n",
    "        return \"con_agent\"\n",
    "\n",
    "print(\"âœ… Agent node functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d589c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-agent debate graph compiled!\n"
     ]
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "#add nodes\n",
    "graph_builder.add_node(\"pro_agent\", pro_agent_node)\n",
    "graph_builder.add_node(\"con_agent\", con_agent_node)\n",
    "\n",
    "# Add conditional routing from pro_agent\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"pro_agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"con_agent\": \"con_agent\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"con_agent\", \n",
    "    should_continue,\n",
    "    {\n",
    "        \"pro_agent\": \"pro_agent\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.set_entry_point(\"pro_agent\")\n",
    "\n",
    "\n",
    "compiled_graph = graph_builder.compile()\n",
    "\n",
    "print(\"âœ… Multi-agent debate graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288889bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 documents to vector store\n",
      "âœ… Test data added to vector database!\n"
     ]
    }
   ],
   "source": [
    "# Add some test data to the vector database\n",
    "test_documents = [\n",
    "    \"Artificial intelligence will significantly improve healthcare outcomes by enabling early disease detection, personalized treatment plans, and reducing medical errors through advanced diagnostic tools.\",\n",
    "    \"AI in healthcare raises serious privacy concerns as it requires access to sensitive patient data, potentially leading to data breaches and unauthorized access to personal medical information.\",\n",
    "    \"Machine learning algorithms can help doctors make more accurate diagnoses by analyzing vast amounts of medical data and identifying patterns that humans might miss.\",\n",
    "    \"The implementation of AI in healthcare is extremely expensive, requiring significant infrastructure investments that many hospitals and clinics cannot afford, potentially widening healthcare disparities.\",\n",
    "    \"AI-powered robotic surgery can perform complex procedures with greater precision than human surgeons, reducing recovery times and improving patient outcomes.\",\n",
    "    \"AI systems in healthcare lack transparency and explainability, making it difficult for doctors and patients to understand how decisions are made, which could lead to medical malpractice issues.\",\n",
    "    \"Telemedicine powered by AI can provide healthcare access to remote and underserved populations, democratizing medical care and reducing healthcare costs.\",\n",
    "    \"AI algorithms can perpetuate existing biases in healthcare data, leading to discriminatory treatment recommendations for certain demographic groups.\",\n",
    "    \"Predictive analytics in AI can help prevent hospital readmissions by identifying high-risk patients and providing proactive care interventions.\",\n",
    "    \"The over-reliance on AI in healthcare could lead to deskilling of medical professionals and reduce the human element that is crucial for patient care and empathy.\"\n",
    "]\n",
    "\n",
    "test_metadata = [\n",
    "    {\"source\": \"healthcare_ai_pros\", \"topic\": \"AI Healthcare Benefits\"},\n",
    "    {\"source\": \"healthcare_ai_cons\", \"topic\": \"AI Healthcare Privacy\"},\n",
    "    {\"source\": \"healthcare_ai_pros\", \"topic\": \"AI Diagnostic Accuracy\"},\n",
    "    {\"source\": \"healthcare_ai_cons\", \"topic\": \"AI Healthcare Costs\"},\n",
    "    {\"source\": \"healthcare_ai_pros\", \"topic\": \"AI Surgical Precision\"},\n",
    "    {\"source\": \"healthcare_ai_cons\", \"topic\": \"AI Transparency Issues\"},\n",
    "    {\"source\": \"healthcare_ai_pros\", \"topic\": \"AI Telemedicine\"},\n",
    "    {\"source\": \"healthcare_ai_cons\", \"topic\": \"AI Bias Concerns\"},\n",
    "    {\"source\": \"healthcare_ai_pros\", \"topic\": \"AI Predictive Analytics\"},\n",
    "    {\"source\": \"healthcare_ai_cons\", \"topic\": \"AI Human Element\"}\n",
    "]\n",
    "\n",
    "# Add documents to vector database\n",
    "pinecone_db.add_documents(test_documents, test_metadata)\n",
    "print(\"âœ… Test data added to vector database!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da23d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test function created!\n"
     ]
    }
   ],
   "source": [
    "# Test function to run the debate\n",
    "def test_debate(claim, max_rounds=4):\n",
    "    \"\"\"Test the RAG debate system with a given claim\"\"\"\n",
    "    \n",
    "    # Initialize the state\n",
    "    initial_state = {\n",
    "        \"claim\": claim,\n",
    "        \"messages\": [],\n",
    "        \"round_number\": 1,\n",
    "        \"max_rounds\": max_rounds,\n",
    "        \"conversation_history\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"ðŸŽ¯ DEBATE TOPIC: {claim}\")\n",
    "    print(f\"ðŸ“Š Rounds: {max_rounds}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ðŸŽ§ Audio will play for each agent's response...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Run the debate\n",
    "        result = compiled_graph.invoke(initial_state)\n",
    "        \n",
    "        # Display final summary\n",
    "        print(\"\\nðŸ DEBATE COMPLETED!\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total exchanges: {len(result['conversation_history'])}\")\n",
    "        print(\"=\" * 80)\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error running debate: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Test function created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaf79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting RAG Debate Test...\n",
      "================================================================================\n",
      "ðŸŽ¯ DEBATE TOPIC: Artificial Intelligence will revolutionize healthcare for the better\n",
      "ðŸ“Š Rounds: 4\n",
      "================================================================================\n",
      "ðŸŽ§ Audio will play for each agent's response...\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¤ PROPONENT (Round 1):\n",
      "--------------------------------------------------\n",
      "Good morning. I am here today to affirm the undeniable truth that artificial intelligence will revolutionize healthcare for the better. This is not a distant-future prediction, but a present-day reality. AI is poised to become the most significant advancement in medicine since the discovery of antibiotics, creating a future where healthcare is more precise, proactive, and personalized for every single patient.\n",
      "\n",
      "My argument is built on the clear and compelling benefits outlined in our evidence.\n",
      "\n",
      "First, AI grants us the unprecedented ability for **early disease detection**. As our supporting evidence states, AI can analyze complex medical dataâ€”from radiological scans to genetic markersâ€”with a speed and accuracy that surpasses human capability (Evidence 1). This means identifying cancers at their most treatable stages, predicting diabetic retinopathy before vision is lost, and flagging early signs of neurological disorders. By catching diseases sooner, we radically improve patient outcomes and save lives.\n",
      "\n",
      "Second, AI will usher in an era of truly **personalized treatment plans** (Evidence 2). The one-size-fits-all approach to medicine is becoming obsolete. AI algorithms can process a patient's unique genetic information, lifestyle, and environment to help doctors design treatments tailored specifically to them. This precision medicine ensures patients receive the most effective therapies with the fewest side effects, moving from a system of guesswork to one of certainty.\n",
      "\n",
      "Finally, AI is a powerful tool for **reducing medical errors** (Evidence 3). Diagnostic mistakes and adverse drug events are significant challenges in healthcare. AI systems act as a vital second set of eyes for clinicians, using \"advanced diagnostic tools\" to verify diagnoses, check for potential drug interactions, and eliminate the risk of human error. This doesn't replace doctors; it empowers them, providing a safety net that directly translates to better, safer care for all.\n",
      "\n",
      "In short, AI is a revolutionary force for good in healthcare. By enabling earlier detection, personalizing treatment, and minimizing errors, it will enhance the capabilities of our medical professionals and forge a healthier future for humanity.\n",
      "\n",
      "ðŸ”Š Playing Proponent's response...\n",
      "\n",
      "ðŸŽ¤ CONPONENT (Round 2):\n",
      "--------------------------------------------------\n",
      "Thank you to my opponent for their opening remarks.\n",
      "\n",
      "My opponent has painted a compelling and optimistic picture of an AI-driven healthcare future, a vision that is directly reflected in the evidence provided. This evidence repeatedly promises that AI \"will significantly improve healthcare outcomes by enabling early disease detection, personalized treatment plans, and reducing medical errors\" (Evidence 1, 2, 3, 4, 5).\n",
      "\n",
      "However, I argue that this utopian promise is precisely the problem. The uncritical optimism of this evidence blinds us to the immense and unavoidable risks. The revolution my opponent advocates for comes at too high a cost.\n",
      "\n",
      "First, let's consider the foundation of these \"personalized treatment plans\" (Evidence 2). AI systems require massive datasets to learn. If this data reflects existing societal biasesâ€”and it invariably willâ€”the AI will not fix health disparities; it will automate and amplify them. The promise of personalization for some will become systemic discrimination for others, codified into the very algorithms meant to help.\n",
      "\n",
      "Second, the goal of \"reducing medical errors through advanced diagnostic tools\" (Evidence 4) creates a dangerous dependency. Over-reliance on these tools risks the de-skilling of our human medical professionals. What happens when an algorithm, trained on past data, encounters a novel disease? What happens when a subtle software bug leads to misdiagnoses on an industrial scale? We are trading the expertise and intuition of trained doctors for the cold, and potentially flawed, logic of a machine.\n",
      "\n",
      "This so-called revolution is not a guaranteed improvement. It is a reckless leap into a future where our healthcare is vulnerable to algorithmic bias, unprecedented system failures, and a chilling erosion of the human element in medicine. The evidence presents a simplistic dream, but the reality is a potential nightmare we are not prepared to face.\n",
      "\n",
      "ðŸ”Š Playing Conponent's response...\n",
      "\n",
      "ðŸŽ¤ PROPONENT (Round 3):\n",
      "--------------------------------------------------\n",
      "Thank you to my opponent for their points. While the concerns raised about the implementation of AI are important topics for discussion, they represent manageable challenges on the road to progress, rather than insurmountable barriers to a healthier future. The core of this debate remains whether AI will revolutionize healthcare *for the better*, and the evidence overwhelmingly confirms that it will.\n",
      "\n",
      "My opponent has likely raised concerns about the potential for bias in AI algorithms and the fear of displacing human doctors. Let's address these directly. The idea that AI will supplant the human element is a fundamental misunderstanding of its role. AI is a tool to augment, not replace, our skilled medical professionals. As the evidence points out, AI provides \"advanced diagnostic tools\" that can analyze thousands of data points in secondsâ€”a task impossible for the human mind (Evidence 1, 5). This frees up doctors to do what they do best: connect with patients, apply critical thinking, and provide empathetic care. AI handles the data; the doctor handles the patient.\n",
      "\n",
      "Furthermore, while algorithmic bias is a real challenge that requires diligent oversight, AI also presents a powerful opportunity to *reduce* existing human bias in medicine. A properly designed AI can deliver objective analysis, leading to the \"personalized treatment plans\" mentioned in our evidence, which are based on a patient's specific data rather than preconceived notions or demographic assumptions (Evidence 2, 4).\n",
      "\n",
      "Ultimately, we must focus on the tangible, life-saving benefits. The evidence consistently shows that AI will lead to better outcomes through three key pathways:\n",
      "1.  **Early Disease Detection:** Spotting cancers and other diseases at their earliest, most treatable stages.\n",
      "2.  **Personalized Treatment:** Moving beyond one-size-fits-all medicine to care tailored to an individualâ€™s unique biology.\n",
      "3.  **Reducing Medical Errors:** Acting as a vital safety net to prevent diagnostic and prescription mistakes. (Evidence 1-5).\n",
      "\n",
      "These are not incremental improvements; they are revolutionary shifts in how we practice medicine. The challenges are not a reason to reject this technology, but a call to implement it thoughtfully to ensure its immense benefits reach everyone.\n",
      "\n",
      "ðŸ”Š Playing Proponent's response...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_debate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_claim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[63], line 22\u001b[0m, in \u001b[0;36mtest_debate\u001b[1;34m(claim, max_rounds)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Run the debate\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Display final summary\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ DEBATE COMPLETED!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\netha\\htv10\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3066\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3069\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3070\u001b[0m     config,\n\u001b[0;32m   3071\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3075\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3076\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3077\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3078\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3079\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3081\u001b[0m ):\n\u001b[0;32m   3082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3083\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\netha\\htv10\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:2657\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2656\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2658\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2659\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2660\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2661\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2662\u001b[0m ):\n\u001b[0;32m   2663\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2664\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2665\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2666\u001b[0m     )\n\u001b[0;32m   2667\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32mc:\\Users\\netha\\htv10\\venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\netha\\htv10\\venv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\netha\\htv10\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\netha\\htv10\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[59], line 13\u001b[0m, in \u001b[0;36mpro_agent_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert to speech with enhanced audio system\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ”Š Playing Proponent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms response...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mplay_agent_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproponent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Update conversation history\u001b[39;00m\n\u001b[0;32m     16\u001b[0m new_entry \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeaker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProponent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: response,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround_number\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     20\u001b[0m }\n",
      "Cell \u001b[1;32mIn[51], line 12\u001b[0m, in \u001b[0;36mplay_agent_audio\u001b[1;34m(text, agent_type)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Play audio with specific voice for agent type\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m voice_id \u001b[38;5;241m=\u001b[39m VOICE_OPTIONS\u001b[38;5;241m.\u001b[39mget(agent_type, VOICE_OPTIONS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproponent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtext_to_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 29\u001b[0m, in \u001b[0;36mtext_to_speech\u001b[1;34m(text, voice_id)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Wait for playback to finish\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pygame\u001b[38;5;241m.\u001b[39mmixer\u001b[38;5;241m.\u001b[39mmusic\u001b[38;5;241m.\u001b[39mget_busy():\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Clean up the temporary file\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test the RAG debate system\n",
    "test_claim = \"Artificial Intelligence will revolutionize healthcare for the better\"\n",
    "\n",
    "print(\"ðŸš€ Starting RAG Debate Test...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run the test\n",
    "result = test_debate(test_claim, max_rounds=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab01f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Testing Eleven Labs audio...\n",
      "Error generating speech: name 'generate' is not defined\n",
      "âœ… Audio test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test the audio functionality\n",
    "print(\"ðŸŽµ Testing Eleven Labs audio...\")\n",
    "test_text = \"Hello! This is a test of the text-to-speech functionality for our debate agents.\"\n",
    "text_to_speech(test_text)\n",
    "print(\"âœ… Audio test completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a1a5a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
